{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.105:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, user_name='fernandomaiscal', artist_name='Kenny Rogers', track_name='All I Ever Need Is You (feat. Dottie West)', liked='1', new_userId='0', new_songId=47914, new_artistId=17547),\n",
       " Row(_c0=1, user_name='fernandomaiscal', artist_name='Geraldo Azevedo', track_name='Dia Branco', liked='1', new_userId='0', new_songId=128432, new_artistId=1637)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lines = spark.read.csv(\"gs://dataset-rs/dataset-last.fm/dataset_lastfm.csv\", header=\"true\",inferSchema=\"true\").rdd\n",
    "lines = spark.read.csv(\"/home/aleja/Documentos/datasets/meu-lastfm/dataset_lastfm_liked_idsCovert.csv\", header=\"true\",inferSchema=\"true\").rdd\n",
    "\n",
    "lines.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dataframe\n",
    "ratings = spark.createDataFrame(lines) \n",
    "#ratings = ratings.withColumn(\"topTracks_playcount\", col(\"topTracks_playcount\").cast('int'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1065102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50% Sample of data \n",
    "df_ratings = ratings.sample(False,fraction=0.9, seed=1)\n",
    "#Drop NaN data \n",
    "df_ratings = df_ratings.na.drop()\n",
    "df_ratings.select('new_userId').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------------+--------------------+-----+----------+----------+------------+\n",
      "|_c0|      user_name|    artist_name|          track_name|liked|new_userId|new_songId|new_artistId|\n",
      "+---+---------------+---------------+--------------------+-----+----------+----------+------------+\n",
      "|  0|fernandomaiscal|   Kenny Rogers|All I Ever Need I...|    1|         0|     47914|       17547|\n",
      "|  1|fernandomaiscal|Geraldo Azevedo|          Dia Branco|    1|         0|    128432|        1637|\n",
      "|  2|fernandomaiscal|    John Lennon|    Gimme Some Truth|    1|         0|      9338|        6482|\n",
      "|  3|fernandomaiscal|    David Bowie|  Station to Station|    1|         0|    170601|        7084|\n",
      "|  5|fernandomaiscal|   Scott Walker|          The Bridge|    1|         0|     23534|       13436|\n",
      "+---+---------------+---------------+--------------------+-----+----------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: long (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- liked: string (nullable = true)\n",
      " |-- new_userId: string (nullable = true)\n",
      " |-- new_songId: long (nullable = true)\n",
      " |-- new_artistId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ratings = df_ratings.withColumn(\"new_userId\", col(\"new_userId\").cast(\"int\"))\n",
    "df_ratings = df_ratings.withColumn(\"new_songId\", col(\"new_songId\").cast(\"int\"))\n",
    "df_ratings = df_ratings.withColumn(\"new_artistId\", col(\"new_artistId\").cast(\"int\"))\n",
    "df_ratings = df_ratings.withColumn(\"liked\", col(\"liked\").cast(\"int\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: long (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- liked: integer (nullable = true)\n",
      " |-- new_userId: integer (nullable = true)\n",
      " |-- new_songId: integer (nullable = true)\n",
      " |-- new_artistId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n. of users:  6227\n",
      "Total n. of artists:  23267\n",
      "Total n. of songs:  198051\n"
     ]
    }
   ],
   "source": [
    "## How many distinct users in data ?\n",
    "\n",
    "uniqueUsers = df_ratings.select('new_userId').distinct().count()\n",
    "print(\"Total n. of users: \", uniqueUsers)\n",
    "\n",
    "## How many distinct artists in data ?\n",
    "\n",
    "uniqueArtists  = df_ratings.select(\"new_artistId\").distinct().count()\n",
    "print(\"Total n. of artists: \", uniqueArtists)\n",
    "\n",
    "## How many distinct music in data ?\n",
    "\n",
    "uniqueSongs  = df_ratings.select(\"new_songId\").distinct().count()\n",
    "print(\"Total n. of songs: \", uniqueSongs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOTAL PLAY COUNT OF EACH TOP_TRACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#song_play1 = df_ratings.selectExpr(\"track_name\",\"artist_name\").groupBy(col('tracks_name'),col('artist_name')).sum(\"Total_count\")\n",
    "#song_play1.orderBy(\"sum(Total_count)\",ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#song_play1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#How many times each user has played a song?\n",
    "# Compute user activity\n",
    "# We are interested in how many playcounts each user has scored.\n",
    "\n",
    "#userActivity =  df_ratings.groupBy(\"new_userId\").sum(\"topTracks_playcount\").collect()\n",
    "#userActivity[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot CDF (or ECDF) of number of play counts per User ID.\n",
    "pdf = pd.DataFrame(data=userActivity)\n",
    "Y=np.sort( pdf[1] )\n",
    "yvals=np.arange(len(Y))/float(len(Y))\n",
    "\n",
    "print(np.arange(len(Y)))\n",
    "\n",
    "plt.plot( Y, yvals )\n",
    "plt.xlabel('Play Counts')\n",
    "plt.xlim(0,30000)   # We shrink the window \n",
    "plt.ylabel('ECDF')\n",
    "plt.grid(True,which=\"both\",ls=\"-\")\n",
    "plt.title('ECDF of number of play counts per User ID')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Additional relevant code\n",
    "percentiles = [0.03, 0.10, 0.25, 0.50, 0.75, 0.90]\n",
    "for p in percentiles:\n",
    "    i = np.where(yvals<=p)[0][-1]    \n",
    "    print(str(p*100),\"percent of the users has less than: \",Y[i],\" play counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compute artist popularity\n",
    "# We are interested in how many playcounts per artist\n",
    "# ATTENTION! Grouping by artistID may be problematic, as stated above.\n",
    "\n",
    "artistPopularity = df_ratings.groupby(\"new_artistId\").sum(\"topTracks_playcount\").collect()\n",
    "\n",
    "pdf = pd.DataFrame(data=artistPopularity)\n",
    "Y=np.sort( pdf[1] )\n",
    "yvals=np.arange(len(Y))/float(len(Y))\n",
    "\n",
    "print(np.arange(len(Y)))\n",
    "\n",
    "plt.plot( Y, yvals )\n",
    "plt.xlabel('Play Counts')\n",
    "plt.xlim(0,2000)\n",
    "plt.ylabel('ECDF')\n",
    "plt.grid(True,which=\"both\",ls=\"-\")\n",
    "plt.title('ECDF of number of play counts per Artist ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compute music popularity\n",
    "# We are interested in how many playcounts per music\n",
    "# ATTENTION! Grouping by artistID may be problematic, as stated above.\n",
    "\n",
    "musicPopularity = df_ratings.groupby(\"new_songId\").sum(\"topTracks_playcount\").collect()\n",
    "\n",
    "pdf = pd.DataFrame(data=musicPopularity)\n",
    "Y=np.sort( pdf[1] )\n",
    "yvals=np.arange(len(Y))/float(len(Y))\n",
    "\n",
    "print(np.arange(len(Y)))\n",
    "\n",
    "plt.plot( Y, yvals )\n",
    "plt.xlabel('Play Counts')\n",
    "plt.xlim(0,1000)\n",
    "plt.ylabel('ECDF')\n",
    "plt.grid(True,which=\"both\",ls=\"-\")\n",
    "plt.title('ECDF of number of play counts per music ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Additional relevant code\n",
    "percentiles = [0.03, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95]\n",
    "for p in percentiles:\n",
    "    i = np.where(yvals<=p)[0][-1]    \n",
    "    print(str(p*100),\"percent of the music has less than: \",Y[i],\" playcount \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total count of  a song listened by users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "song_play =df_ratings.groupBy(\"topTracks_name\", \"topTracks_artist_name\").count()\n",
    "song_play.orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_ratings.selectExpr(\"new_songId\", \"new_artistId\",'topTracks_playcount').distinct().describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "grouped_sum0 = song_play.selectExpr('count')\n",
    "grouped_sum0 = grouped_sum0.groupBy().sum().collect()[0][0]\n",
    "grouped_sum0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "y = song_play.withColumn(\"porcentage\", (song_play['count']/grouped_sum0)*100)\n",
    "#song_play.selectExpr((song_play['count'] / grouped_sum0)*100)\n",
    "y.orderBy(\"count\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create music data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[new_songId: int, track_name: string, new_artistId: int, artist_name: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_data =  df_ratings.selectExpr(\"new_songId\",\"track_name\",\"new_artistId\",\"artist_name\")\n",
    "music_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset Training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|new_userId|new_songId|liked|\n",
      "+----------+----------+-----+\n",
      "|      null|         1| null|\n",
      "|      null|         1| null|\n",
      "|         0|      1055|    1|\n",
      "|         0|      1078|    1|\n",
      "|         0|      1443|    1|\n",
      "|         0|      1819|    1|\n",
      "|         0|      2571|    1|\n",
      "|         0|      4642|    1|\n",
      "|         0|      4845|    1|\n",
      "|         0|      5121|    1|\n",
      "+----------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sub_rating_data = df_ratings_with_int_ids.select(\"new_userId\",\"new_songId\",\"topTracks_playcount\")\n",
    "sub_rating_data = df_ratings.select(\"new_userId\",\"new_songId\",\"liked\")\n",
    "\n",
    "sub_rating_data.orderBy(col('new_userId'),col('new_songId')).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|new_userId|new_songId|liked|\n",
      "+----------+----------+-----+\n",
      "|         0|      1055|    1|\n",
      "|         0|      1078|    1|\n",
      "|         0|      1443|    1|\n",
      "|         0|      1819|    1|\n",
      "|         0|      2571|    1|\n",
      "|         0|      4642|    1|\n",
      "|         0|      4845|    1|\n",
      "|         0|      5121|    1|\n",
      "|         0|      5332|    1|\n",
      "|         0|      5438|    1|\n",
      "+----------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_rating_data = sub_rating_data.na.drop()\n",
    "\n",
    "\n",
    "sub_rating_data.orderBy(col('new_userId'),col('new_songId')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- new_userId: integer (nullable = true)\n",
      " |-- new_songId: integer (nullable = true)\n",
      " |-- liked: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(training, test) = sub_rating_data.randomSplit([0.8, 0.2])\n",
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training.orderBy(col('new_userId'),col('new_songId')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test.orderBy(col('new_userId'),col('new_songId')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als = ALS(rank=10, maxIter=10, regParam=0.01, alpha=0.5, implicitPrefs=False, userCol=\"new_userId\", itemCol=\"new_songId\", ratingCol=\"liked\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Predictions-  test model\n",
    "predictions = model.transform(test)\n",
    "\n",
    "#predictions.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- new_userId: integer (nullable = true)\n",
      " |-- new_songId: integer (nullable = true)\n",
      " |-- liked: integer (nullable = true)\n",
      " |-- prediction: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+----------+\n",
      "|new_userId|new_songId|liked|prediction|\n",
      "+----------+----------+-----+----------+\n",
      "|      1708|       148|    1| 0.9932618|\n",
      "|      1978|       148|    1| 0.9956291|\n",
      "|      4738|       148|    1| 0.9882174|\n",
      "|      4212|       148|    1|0.99797666|\n",
      "|      1846|       148|    1|  0.976412|\n",
      "|      2641|       148|    1| 0.9949031|\n",
      "|      2624|       148|    1| 1.0010266|\n",
      "|      6181|       833|    1| 0.9924753|\n",
      "|      1658|       833|    1|0.96309763|\n",
      "|      5729|      1342|    1|0.98549324|\n",
      "|       986|      1959|    1| 0.9639661|\n",
      "|      1894|      2122|    1|0.97267795|\n",
      "|      3882|      3749|    1| 0.9971295|\n",
      "|      4829|      4900|    1| 1.0190439|\n",
      "|       822|      4900|    1|0.99367636|\n",
      "|      1613|      4900|    1| 1.0287379|\n",
      "|      1219|      4900|    1|0.99045247|\n",
      "|       543|      4900|    1|0.98880726|\n",
      "|      4071|      5518|    1| 0.9558742|\n",
      "|      1108|      6336|    1| 0.9784731|\n",
      "+----------+----------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.08053935843481734\n",
      "mae = 0.027569026808437702\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"liked\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions.na.drop(), {evaluator.metricName :\"rmse\"})\n",
    "mae =  evaluator.evaluate(predictions.na.drop(), {evaluator.metricName :\"mae\"})\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "print(\"mae = \" + str(mae))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x= model.recommendForAllUsers(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|new_userId|recommendations                                                                                                                                                                                  |\n",
      "+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1580      |[[68207,1.1615322], [75263,1.1457906], [126087,1.136142], [101064,1.1299186], [148559,1.1091481], [49892,1.1052668], [135392,1.0986837], [173982,1.0947129], [15461,1.0943902], [8512,1.0808991]]|\n",
      "+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "\n",
    "def recommendMusic(model, user, nbRecommendations):\n",
    "     # Create a Spark DataFrame with the specified user and all the movies listed in the ratings DataFrame\n",
    "    dataSet = df_ratings.select(\"new_songId\").distinct().withColumn(\"new_userId\", lit(user))\n",
    "\n",
    "    # Create a Spark DataFrame with the movies that have already been rated by this user\n",
    "    musicAlreadyRated = df_ratings.filter(df_ratings.new_userId == user).select(\"new_songId\", \"new_userId\")\n",
    "\n",
    "    # Apply the recommender system to the data set without the already rated movies to predict ratings\n",
    "    predictions = model.transform(dataSet.subtract(musicAlreadyRated)).dropna().select(\"new_songId\", \"prediction\").orderBy(\"prediction\", ascending=False).limit(nbRecommendations)\n",
    "    \n",
    "    # Join with the ratings DataFrame to get the music titles and genres\n",
    "    recommendations = predictions.join(music_data, predictions.new_songId == music_data.new_songId).select(predictions.new_songId, music_data.track_name, music_data.artist_name, predictions.prediction).orderBy(\"prediction\", ascending=False).distinct()\n",
    "    recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 367:\n",
      "+----------+-------------------------------------------------+------------------+----------+\n",
      "|new_songId|track_name                                       |artist_name       |prediction|\n",
      "+----------+-------------------------------------------------+------------------+----------+\n",
      "|68207     |Fishing Bird (Empty Gutted in the Evening Breeze)|Grouper           |1.1550529 |\n",
      "|126087    |Beyond the Veil                                  |Fall of Efrafa    |1.1450307 |\n",
      "|75263     |Sarajevo                                         |Max Richter       |1.1344285 |\n",
      "|101064    |Odessa                                           |Animals as Leaders|1.1140392 |\n",
      "|49892     |Constants Are Changing                           |Boards of Canada  |1.0984461 |\n",
      "|148559    |Kő koppan                                        |Thy Catafalque    |1.0947309 |\n",
      "|135392    |Abysmo                                           |Moonspell         |1.0907323 |\n",
      "|166403    |Nascence                                         |Austin Wintory    |1.0901837 |\n",
      "|15461     |Stay With Me                                     |Clint Mansell     |1.0851741 |\n",
      "|142780    |A Long Walk                                      |Jill Scott        |1.0753962 |\n",
      "+----------+-------------------------------------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Recommendations for user 1:\")\n",
    "recommendMusic(model,1,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 48:\n",
      "+----------+-------------------------------------------------+------------------+----------+\n",
      "|new_songId|track_name                                       |artist_name       |prediction|\n",
      "+----------+-------------------------------------------------+------------------+----------+\n",
      "|166403    |Nascence                                         |Austin Wintory    |1.1570499 |\n",
      "|68207     |Fishing Bird (Empty Gutted in the Evening Breeze)|Grouper           |1.128329  |\n",
      "|49892     |Constants Are Changing                           |Boards of Canada  |1.1059399 |\n",
      "|101064    |Odessa                                           |Animals as Leaders|1.0907942 |\n",
      "|126087    |Beyond the Veil                                  |Fall of Efrafa    |1.0852691 |\n",
      "|173982    |Autumn Leaves                                    |Bill Evans        |1.0836991 |\n",
      "|44150     |Give In                                          |The Bravery       |1.0811712 |\n",
      "|52765     |Electricity                                      |The Avalanches    |1.0798715 |\n",
      "|135392    |Abysmo                                           |Moonspell         |1.0776013 |\n",
      "|15461     |Stay With Me                                     |Clint Mansell     |1.0765756 |\n",
      "+----------+-------------------------------------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Recommendations for user 48:\")\n",
    "recommendMusic(model,8,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### para mejorar la Acuracia del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "evaluations = []\n",
    "#rank [10:50], lambda [1.0, 0.0001], alpha [1.0, 40.0]\n",
    "\n",
    "for rank in [10,50]:\n",
    "    for lambda_ in [1.0,0.0001]:\n",
    "        for alpha in [1.0,40.0]:\n",
    "            print(\"Train model with rank=%d lambda_=%f alpha=%f\" % (rank, lambda_, alpha))\n",
    "            model = ALS(rank=rank, maxIter=15, regParam=lambda_, alpha=alpha, implicitPrefs=True,  \n",
    "                        userCol=\"new_userId\", itemCol=\"new_songId\", ratingCol=\"topTracks_playcount\", coldStartStrategy=\"drop\").fit(training)\n",
    "            #model = als.fit(training)\n",
    "            predictions = model.transform(test)\n",
    "            evaluator = RegressionEvaluator(labelCol=\"topTracks_playcount\", predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions.na.drop(), {evaluator.metricName :\"rmse\"})\n",
    "            \n",
    "            evaluations.append(((rank, lambda_, alpha), rmse))\n",
    "            \n",
    "            #unpersist(model)\n",
    "\n",
    "evaluations.sort(key=lambda r:r[1], reverse = True)\n",
    "                 \n",
    "evalDataFrame = pd.DataFrame(data=evaluations)\n",
    "print(evalDataFrame)\n",
    "\n",
    "\n",
    "            \n",
    "#training.unpersist()\n",
    "#test.unpersist()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#performance \n",
    "\n",
    "def kfoldALS(data, k=3, userCol=\"new_userId\", itemCol=\"new_songId\", ratingCol=\"topTracks_playcount\", metricName=\"rmse\",labelCol=\"topTracks_playcount\"):\n",
    "    evaluations = []\n",
    "    weights = [1.0] * k\n",
    "    splits = data.randomSplit(weights)\n",
    "    for i in range(0, k):  \n",
    "        testingSet = splits[i]\n",
    "        trainingSet = spark.createDataFrame(sc.emptyRDD(), data.schema)\n",
    "        for j in range(0, k):\n",
    "            if i == j:\n",
    "                continue\n",
    "            else:\n",
    "                trainingSet = trainingSet.union(splits[j])\n",
    "        als = ALS(userCol=userCol, itemCol=itemCol, ratingCol=ratingCol)\n",
    "        model = als.fit(trainingSet)\n",
    "        predictions = model.transform(testingSet)\n",
    "        evaluator = RegressionEvaluator(metricName=metricName, labelCol=labelCol, predictionCol=\"prediction\")\n",
    "        evaluation = evaluator.evaluate(predictions.na.drop())\n",
    "        print (\"Loop \" + str(i+1) + \": \" + metricName + \" = \" + str(evaluation))\n",
    "        evaluations.append(evaluation)\n",
    "    return sum(evaluations)/float(len(evaluations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print (\"RMSE = \" + str(kfoldALS(sub_rating_data, k=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Letter|Number|\n",
      "+------+------+\n",
      "|     A|    20|\n",
      "|     B|    30|\n",
      "|     D|    80|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"A\", 20), (\"B\", 30), (\"D\", 80)],[\"Letter\", \"Number\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(Number)=130)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = df.groupBy().sum().collect()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
